#!/bin/bash
# Copyright (C) 2024 The Android Open Source Project
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Script to collect the ravenwood "stats" CVS files and create a single file.

set -e

# This script's directory.
SCRIPT_DIR="$(realpath ${0%/*})"

# Parse the options.

diff_base=""
while getopts "d:" opt; do
case "$opt" in
    d)
        # If this flag is provided, diff the newly generated CSV against this file.
        diff_base="$OPTARG"
        ;;
    '?')
        exit 1
        ;;
esac
done
shift $(($OPTIND - 1))

# Output files
out_dir=/tmp/ravenwood
apis=$out_dir/ravenwood-apis-all.csv
keep_all_dir=$out_dir/ravenwood-keep-all/
dump_dir=$out_dir/ravenwood-dump/

rm -fr $out_dir
mkdir -p $out_dir
mkdir -p $keep_all_dir
mkdir -p $dump_dir

# Current time.
timestamp="$(date --iso-8601=seconds)"

# The input CSV files are generated by different build modules, so collecting
# them would be painful.
#
# So instead, we use a dummy sh_test_host "ravenwood-stats-checker" with
# all the input files as its data files. So if we build this module, soong
# will copy this script to its test output directory, along with all the data files,
# so we can now just copy all the *.csv, *.txt files from this single directory.
#
# So first, we need to find this output directory, which is in the module-info.json
# file. So we use JQ to find it.
#
# The json contains something like the following, so we need to find the script path.
#
# ---
# "ravenwood-stats-checker" : {
#  :
#  "installed": [
#    "out/host/linux-x86/nativetest64/ravenwood-stats-checker/framework-configinfrastructure_apis.csv",
#    "out/host/linux-x86/nativetest64/ravenwood-stats-checker/framework-configinfrastructure_dump.txt",
#      :
#    "out/host/linux-x86/nativetest64/ravenwood-stats-checker/ravenwood-stats-checker" <-- need to find this.
#  ],
#  :
#},
# ---
checker=ravenwood-stats-checker
minfo=$OUT/module-info.json

checker_path="$(
    jq -r ".\"$checker\".installed.[] | select(endswith(\"/$checker\"))" \
        $minfo
)"

if [[ "$checker_path" == "" ]] ; then
    echo "Error: '$checker' script not found in $minfo"
    exit 1
fi

# This is the directory where our input files are.
files_dir="$ANDROID_BUILD_TOP/$(dirname "$checker_path")/"

# Clear the directory before (re-)building the script, to make sure we won't have stale files.
rm -fr "$files_dir"

# Then build it, which will also collect the input files in $files_dir.
echo "Files directory is: $files_dir"

echo "Collecting the input files..."
m $checker

# Run a command after printing it.
run() {
    echo "Running: $*" 1>&2
    "$@"
}

# Just cat a CSV file, but with two extra columns prepended:
# - Jar module name (first argument)
# - Timestamp
dump() {
    local jar="$1"
    local file="$2"

    # Remove the header row, and prepend the columns.
    sed -e '1d' -e "s/^/$jar,$timestamp,/" "$file"
}

collect_apis() {
    local out="$1"
    {
        # Copy the header, with the first two columns appended.
        echo -n "Jar,Generated Date,"
        head -n 1 "$files_dir"/hoststubgen_framework-minus-apex_apis.csv

        # Dump each module.
        dump "framework-minus-apex"  "$files_dir"/hoststubgen_framework-minus-apex_apis.csv
        dump "service.core"  "$files_dir"/hoststubgen_services.core_apis.csv
        dump "framework-configinfrastructure"  "$files_dir"/framework-configinfrastructure_apis.csv
        dump "framework-statsd" "$files_dir"/framework-statsd_apis.csv
    } > "$out"

    echo "API CVS created at $out (import it as 'ravenwood_supported_apis3')"
}

do_main() {
    collect_apis $apis

    # Collect keep_all files.
    cp "$files_dir"/*keep_all.txt $keep_all_dir
    echo "Keep all files created at:"
    find $keep_all_dir -type f

    # Collect dump files.
    cp "$files_dir"/*dump.txt $dump_dir
    echo "Dump files created at:"
    find $dump_dir -type f
}

# Run the main routine.
do_main

# Main routine done.

#---------------------------------------------------------------------
# Next, if -d (diff base) is provided, take a diff against that file.

if [[ "$diff_base" == "" ]] ; then
    exit 0
fi

echo
echo "Taking a diff against $diff_base ..."

# Flatten a CSV (expand each column in a separate line) for a better diff.
# (Also remove the timestamp.)
flatten() {
    local csv="$1"
    local to="$2"

    echo "Flattening $csv to $to ..."
    # "grep -v" to remove timestamps.
    "$SCRIPT_DIR"/csv-flattener.py "$csv" | grep -v "^  20[0-9][0-9]-[0-9][0-9]" > "$to"
}

do_diff() {
    local f1="$1"
    local f2="$2"

    # Generate flattened text files from the old and new CSVs.
    flatten "$f1" "$f1.txt"
    flatten "$f2" "$f2.txt"

    # Then take a diff.
    # ("|| true" for ignoring the status code)
    run ${DIFF_CMD:-diff} -U 10 "$f1.txt" "$f2.txt" || true
}

do_diff "$diff_base" "$apis"